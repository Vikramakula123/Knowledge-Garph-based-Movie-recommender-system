{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f03766",
   "metadata": {},
   "source": [
    "### Recommendation Using Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513b4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a2d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "url= 'bolt://localhost:7687'\n",
    "user = 'neo4j'\n",
    "password = 'password'\n",
    "\n",
    "driver = GraphDatabase.driver(url, auth=(user, password))\n",
    "\n",
    "def fetch_data(query, params={}):\n",
    "  with driver.session(database = 'neo4j') as session:\n",
    "    result = session.run(query, params)\n",
    "    return pd.DataFrame([r.values() for r in result], columns=result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147cf2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeProjection</th>\n",
       "      <th>relationshipProjection</th>\n",
       "      <th>graphName</th>\n",
       "      <th>nodeCount</th>\n",
       "      <th>relationshipCount</th>\n",
       "      <th>projectMillis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Movie': {'label': 'Movie', 'properties': {}}...</td>\n",
       "      <td>{'ACTED_IN': {'orientation': 'UNDIRECTED', 'ag...</td>\n",
       "      <td>movies</td>\n",
       "      <td>93004</td>\n",
       "      <td>370880</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      nodeProjection  \\\n",
       "0  {'Movie': {'label': 'Movie', 'properties': {}}...   \n",
       "\n",
       "                              relationshipProjection graphName  nodeCount  \\\n",
       "0  {'ACTED_IN': {'orientation': 'UNDIRECTED', 'ag...    movies      93004   \n",
       "\n",
       "   relationshipCount  projectMillis  \n",
       "0             370880            288  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data(\"\"\"\n",
    "CALL gds.graph.project('movies', ['Movie', 'Person'], \n",
    "  {ACTED_IN: {orientation:'UNDIRECTED'}, DIRECTED: {orientation:'UNDIRECTED'}})\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b6d751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeCount</th>\n",
       "      <th>nodePropertiesWritten</th>\n",
       "      <th>preProcessingMillis</th>\n",
       "      <th>computeMillis</th>\n",
       "      <th>writeMillis</th>\n",
       "      <th>configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93004</td>\n",
       "      <td>93004</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>609</td>\n",
       "      <td>{'writeConcurrency': 4, 'nodeSelfInfluence': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodeCount  nodePropertiesWritten  preProcessingMillis  computeMillis  \\\n",
       "0      93004                  93004                    0             94   \n",
       "\n",
       "   writeMillis                                      configuration  \n",
       "0          609  {'writeConcurrency': 4, 'nodeSelfInfluence': 0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data(\"\"\"\n",
    "CALL gds.fastRP.write('movies', {writeProperty:'fastrp', embeddingDimension:56})\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d888d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_node(cypher, index_col, encoders=None, **kwargs):\n",
    "    # Execute the cypher query and retrieve data from Neo4j\n",
    "    df = fetch_data(cypher)\n",
    "    df.set_index(index_col, inplace=True)\n",
    "    # Define node mapping\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    # Define node features\n",
    "    x = None\n",
    "    if encoders is not None:\n",
    "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        x = torch.cat(xs, dim=-1)\n",
    "\n",
    "    return x, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99723fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edge(cypher, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
    "                  encoders=None, **kwargs):\n",
    "    # Execute the cypher query and retrieve data from Neo4j\n",
    "    df = fetch_data(cypher)\n",
    "    # Define edge index\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "    # Define edge features\n",
    "    edge_attr = None\n",
    "    if encoders is not None:\n",
    "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
    "\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f5a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceEncoder(object):\n",
    "    # The 'SequenceEncoder' encodes raw column strings into embeddings.\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, df):\n",
    "        x = self.model.encode(df.values, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=self.device)\n",
    "        return x.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3070e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenresEncoder(object):\n",
    "    # The 'GenreEncoder' splits the raw column strings by 'sep' and converts\n",
    "    # individual elements to categorical labels.\n",
    "    def __init__(self, sep='|'):\n",
    "        self.sep = sep\n",
    "\n",
    "    def __call__(self, df):\n",
    "        genres = set(g for col in df.values for g in col.split(self.sep))\n",
    "        mapping = {genre: i for i, genre in enumerate(genres)}\n",
    "\n",
    "        x = torch.zeros(len(df), len(mapping))\n",
    "        for i, col in enumerate(df.values):\n",
    "            for genre in col.split(self.sep):\n",
    "                x[i, mapping[genre]] = 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc6ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityEncoder(object):\n",
    "    # The 'IdentityEncoder' takes the raw column values and converts them to\n",
    "    # PyTorch tensors.\n",
    "    def __init__(self, dtype=None, is_list=False):\n",
    "        self.dtype = dtype\n",
    "        self.is_list = is_list\n",
    "\n",
    "    def __call__(self, df):\n",
    "        if self.is_list:\n",
    "            return torch.stack([torch.tensor(el) for el in df.values])\n",
    "        return torch.from_numpy(df.values).to(self.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77b123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "MATCH (u:User) RETURN u.userId AS userId\n",
    "\"\"\"\n",
    "\n",
    "user_x, user_mapping = load_node(user_query, index_col='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352a97c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ff864609114934b0e27c9de226340b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_query = \"\"\"\n",
    "MATCH (m:Movie)-[:IN_GENRE]->(genre:Genre)\n",
    "WITH m, collect(genre.name) AS genres_list\n",
    "RETURN m.movieId AS movieId, m.title AS title, apoc.text.join(genres_list, '|') AS genres, m.fastrp AS fastrp\n",
    "\"\"\"\n",
    "\n",
    "movie_x, movie_mapping = load_node(\n",
    "    movie_query, \n",
    "    index_col='movieId', encoders={\n",
    "        'title': SequenceEncoder(),\n",
    "        'genres': GenresEncoder(),\n",
    "        'fastrp': IdentityEncoder(is_list=True)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7e2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_query = \"\"\"\n",
    "MATCH (u:User)-[r:RATED]->(m:Movie) \n",
    "RETURN u.userId AS userId, m.movieId AS movieId, r.rating AS rating\n",
    "\"\"\"\n",
    "\n",
    "edge_index, edge_label = load_edge(\n",
    "    rating_query,\n",
    "    src_index_col='userId',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='movieId',\n",
    "    dst_mapping=movie_mapping,\n",
    "    encoders={'rating': IdentityEncoder(dtype=torch.long)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c69c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1muser\u001b[0m={ x=[671, 671] },\n",
       "  \u001b[1mmovie\u001b[0m={ x=[9047, 460] },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 79522],\n",
       "    edge_label=[79522]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(len(user_mapping), device=device)\n",
    "# Add movie node features\n",
    "data['movie'].x = movie_x\n",
    "# Add ratings between users and movies\n",
    "data['user', 'rates', 'movie'].edge_index = edge_index\n",
    "data['user', 'rates', 'movie'].edge_label = edge_label\n",
    "data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e46bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ToUndirected()(data)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "\n",
    "# 2. Perform a link-level split into training, validation, and test edges.\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "709bbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "962fcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.bincount(train_data['user', 'movie'].edge_label)\n",
    "weight = weight.max() / weight\n",
    "\n",
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05f003d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hidden_channels=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be280381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to lazy initialization, we need to run one model step so the number\n",
    "# of parameters can be inferred:\n",
    "with torch.no_grad():\n",
    "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c0eb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'rates', 'movie'].edge_label_index)\n",
    "    target = train_data['user', 'rates', 'movie'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a223916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'rates', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'rates', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31a3a244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 18.9491, Train: 2.9724, Val: 2.9882, Test: 2.9685\n",
      "Epoch: 002, Loss: 13.8319, Train: 1.6203, Val: 1.6396, Test: 1.6231\n",
      "Epoch: 003, Loss: 6.5224, Train: 1.9350, Val: 1.8984, Test: 1.9186\n",
      "Epoch: 004, Loss: 30.0833, Train: 1.1109, Val: 1.1131, Test: 1.1093\n",
      "Epoch: 005, Loss: 7.4977, Train: 2.0267, Val: 2.0450, Test: 2.0273\n",
      "Epoch: 006, Loss: 7.6556, Train: 2.6342, Val: 2.6499, Test: 2.6310\n",
      "Epoch: 007, Loss: 11.1286, Train: 2.8713, Val: 2.8859, Test: 2.8668\n",
      "Epoch: 008, Loss: 12.9613, Train: 2.9398, Val: 2.9543, Test: 2.9351\n",
      "Epoch: 009, Loss: 13.5375, Train: 2.9298, Val: 2.9444, Test: 2.9253\n",
      "Epoch: 010, Loss: 13.4481, Train: 2.8695, Val: 2.8846, Test: 2.8657\n",
      "Epoch: 011, Loss: 12.9363, Train: 2.7591, Val: 2.7748, Test: 2.7562\n",
      "Epoch: 012, Loss: 12.0402, Train: 2.5818, Val: 2.5983, Test: 2.5804\n",
      "Epoch: 013, Loss: 10.7137, Train: 2.2963, Val: 2.3144, Test: 2.2975\n",
      "Epoch: 014, Loss: 8.8729, Train: 1.8663, Val: 1.8863, Test: 1.8716\n",
      "Epoch: 015, Loss: 6.8205, Train: 1.3269, Val: 1.3466, Test: 1.3372\n",
      "Epoch: 016, Loss: 5.7086, Train: 1.0644, Val: 1.0686, Test: 1.0711\n",
      "Epoch: 017, Loss: 7.2351, Train: 1.1262, Val: 1.1211, Test: 1.1282\n",
      "Epoch: 018, Loss: 8.5299, Train: 1.0555, Val: 1.0607, Test: 1.0635\n",
      "Epoch: 019, Loss: 7.0665, Train: 1.1582, Val: 1.1756, Test: 1.1705\n",
      "Epoch: 020, Loss: 5.6290, Train: 1.4380, Val: 1.4582, Test: 1.4481\n",
      "Epoch: 021, Loss: 5.4905, Train: 1.6841, Val: 1.7037, Test: 1.6914\n",
      "Epoch: 022, Loss: 5.9921, Train: 1.8200, Val: 1.8388, Test: 1.8256\n",
      "Epoch: 023, Loss: 6.4228, Train: 1.8509, Val: 1.8693, Test: 1.8561\n",
      "Epoch: 024, Loss: 6.5179, Train: 1.7903, Val: 1.8089, Test: 1.7962\n",
      "Epoch: 025, Loss: 6.2612, Train: 1.6513, Val: 1.6703, Test: 1.6587\n",
      "Epoch: 026, Loss: 5.7641, Train: 1.4525, Val: 1.4718, Test: 1.4622\n",
      "Epoch: 027, Loss: 5.2368, Train: 1.2373, Val: 1.2557, Test: 1.2494\n",
      "Epoch: 028, Loss: 4.9605, Train: 1.0800, Val: 1.0949, Test: 1.0929\n",
      "Epoch: 029, Loss: 5.1084, Train: 1.0222, Val: 1.0323, Test: 1.0339\n",
      "Epoch: 030, Loss: 5.4362, Train: 1.0169, Val: 1.0255, Test: 1.0278\n",
      "Epoch: 031, Loss: 5.4229, Train: 1.0431, Val: 1.0539, Test: 1.0540\n",
      "Epoch: 032, Loss: 5.0241, Train: 1.1294, Val: 1.1429, Test: 1.1400\n",
      "Epoch: 033, Loss: 4.6742, Train: 1.2556, Val: 1.2700, Test: 1.2649\n",
      "Epoch: 034, Loss: 4.5977, Train: 1.3676, Val: 1.3818, Test: 1.3754\n",
      "Epoch: 035, Loss: 4.6884, Train: 1.4294, Val: 1.4430, Test: 1.4362\n",
      "Epoch: 036, Loss: 4.7632, Train: 1.4300, Val: 1.4427, Test: 1.4362\n",
      "Epoch: 037, Loss: 4.7141, Train: 1.3737, Val: 1.3851, Test: 1.3796\n",
      "Epoch: 038, Loss: 4.5392, Train: 1.2781, Val: 1.2873, Test: 1.2834\n",
      "Epoch: 039, Loss: 4.3235, Train: 1.1756, Val: 1.1813, Test: 1.1794\n",
      "Epoch: 040, Loss: 4.1940, Train: 1.1035, Val: 1.1051, Test: 1.1051\n",
      "Epoch: 041, Loss: 4.2247, Train: 1.0781, Val: 1.0767, Test: 1.0780\n",
      "Epoch: 042, Loss: 4.3163, Train: 1.0856, Val: 1.0833, Test: 1.0847\n",
      "Epoch: 043, Loss: 4.2786, Train: 1.1192, Val: 1.1177, Test: 1.1180\n",
      "Epoch: 044, Loss: 4.1238, Train: 1.1785, Val: 1.1787, Test: 1.1779\n",
      "Epoch: 045, Loss: 4.0168, Train: 1.2479, Val: 1.2496, Test: 1.2482\n",
      "Epoch: 046, Loss: 4.0151, Train: 1.3019, Val: 1.3043, Test: 1.3026\n",
      "Epoch: 047, Loss: 4.0575, Train: 1.3227, Val: 1.3252, Test: 1.3235\n",
      "Epoch: 048, Loss: 4.0667, Train: 1.3076, Val: 1.3095, Test: 1.3080\n",
      "Epoch: 049, Loss: 4.0163, Train: 1.2677, Val: 1.2685, Test: 1.2674\n",
      "Epoch: 050, Loss: 3.9414, Train: 1.2222, Val: 1.2217, Test: 1.2212\n",
      "Epoch: 051, Loss: 3.9009, Train: 1.1892, Val: 1.1876, Test: 1.1878\n",
      "Epoch: 052, Loss: 3.9176, Train: 1.1753, Val: 1.1734, Test: 1.1740\n",
      "Epoch: 053, Loss: 3.9415, Train: 1.1789, Val: 1.1777, Test: 1.1782\n",
      "Epoch: 054, Loss: 3.9133, Train: 1.1987, Val: 1.1990, Test: 1.1987\n",
      "Epoch: 055, Loss: 3.8525, Train: 1.2303, Val: 1.2324, Test: 1.2313\n",
      "Epoch: 056, Loss: 3.8173, Train: 1.2610, Val: 1.2647, Test: 1.2630\n",
      "Epoch: 057, Loss: 3.8182, Train: 1.2757, Val: 1.2805, Test: 1.2785\n",
      "Epoch: 058, Loss: 3.8199, Train: 1.2664, Val: 1.2716, Test: 1.2695\n",
      "Epoch: 059, Loss: 3.7947, Train: 1.2359, Val: 1.2412, Test: 1.2392\n",
      "Epoch: 060, Loss: 3.7519, Train: 1.1974, Val: 1.2022, Test: 1.2011\n",
      "Epoch: 061, Loss: 3.7253, Train: 1.1684, Val: 1.1730, Test: 1.1726\n",
      "Epoch: 062, Loss: 3.7218, Train: 1.1583, Val: 1.1632, Test: 1.1631\n",
      "Epoch: 063, Loss: 3.7085, Train: 1.1644, Val: 1.1703, Test: 1.1697\n",
      "Epoch: 064, Loss: 3.6770, Train: 1.1810, Val: 1.1880, Test: 1.1869\n",
      "Epoch: 065, Loss: 3.6497, Train: 1.1984, Val: 1.2065, Test: 1.2048\n",
      "Epoch: 066, Loss: 3.6373, Train: 1.2071, Val: 1.2157, Test: 1.2141\n",
      "Epoch: 067, Loss: 3.6266, Train: 1.2018, Val: 1.2107, Test: 1.2095\n",
      "Epoch: 068, Loss: 3.6059, Train: 1.1850, Val: 1.1937, Test: 1.1933\n",
      "Epoch: 069, Loss: 3.5795, Train: 1.1644, Val: 1.1729, Test: 1.1734\n",
      "Epoch: 070, Loss: 3.5617, Train: 1.1502, Val: 1.1587, Test: 1.1598\n",
      "Epoch: 071, Loss: 3.5528, Train: 1.1485, Val: 1.1574, Test: 1.1586\n",
      "Epoch: 072, Loss: 3.5361, Train: 1.1577, Val: 1.1675, Test: 1.1683\n",
      "Epoch: 073, Loss: 3.5114, Train: 1.1716, Val: 1.1823, Test: 1.1825\n",
      "Epoch: 074, Loss: 3.4926, Train: 1.1816, Val: 1.1930, Test: 1.1929\n",
      "Epoch: 075, Loss: 3.4796, Train: 1.1820, Val: 1.1939, Test: 1.1937\n",
      "Epoch: 076, Loss: 3.4632, Train: 1.1728, Val: 1.1851, Test: 1.1849\n",
      "Epoch: 077, Loss: 3.4417, Train: 1.1597, Val: 1.1723, Test: 1.1723\n",
      "Epoch: 078, Loss: 3.4223, Train: 1.1497, Val: 1.1627, Test: 1.1628\n",
      "Epoch: 079, Loss: 3.4078, Train: 1.1477, Val: 1.1614, Test: 1.1613\n",
      "Epoch: 080, Loss: 3.3913, Train: 1.1541, Val: 1.1684, Test: 1.1682\n",
      "Epoch: 081, Loss: 3.3705, Train: 1.1639, Val: 1.1788, Test: 1.1784\n",
      "Epoch: 082, Loss: 3.3525, Train: 1.1705, Val: 1.1860, Test: 1.1855\n",
      "Epoch: 083, Loss: 3.3373, Train: 1.1697, Val: 1.1858, Test: 1.1853\n",
      "Epoch: 084, Loss: 3.3201, Train: 1.1619, Val: 1.1787, Test: 1.1782\n",
      "Epoch: 085, Loss: 3.3013, Train: 1.1521, Val: 1.1696, Test: 1.1691\n",
      "Epoch: 086, Loss: 3.2845, Train: 1.1456, Val: 1.1637, Test: 1.1633\n",
      "Epoch: 087, Loss: 3.2690, Train: 1.1450, Val: 1.1638, Test: 1.1634\n",
      "Epoch: 088, Loss: 3.2517, Train: 1.1492, Val: 1.1686, Test: 1.1683\n",
      "Epoch: 089, Loss: 3.2340, Train: 1.1540, Val: 1.1739, Test: 1.1737\n",
      "Epoch: 090, Loss: 3.2180, Train: 1.1549, Val: 1.1756, Test: 1.1755\n",
      "Epoch: 091, Loss: 3.2022, Train: 1.1507, Val: 1.1722, Test: 1.1723\n",
      "Epoch: 092, Loss: 3.1855, Train: 1.1435, Val: 1.1660, Test: 1.1662\n",
      "Epoch: 093, Loss: 3.1694, Train: 1.1375, Val: 1.1609, Test: 1.1611\n",
      "Epoch: 094, Loss: 3.1535, Train: 1.1349, Val: 1.1591, Test: 1.1594\n",
      "Epoch: 095, Loss: 3.1375, Train: 1.1352, Val: 1.1601, Test: 1.1605\n",
      "Epoch: 096, Loss: 3.1219, Train: 1.1362, Val: 1.1618, Test: 1.1624\n",
      "Epoch: 097, Loss: 3.1065, Train: 1.1356, Val: 1.1620, Test: 1.1628\n",
      "Epoch: 098, Loss: 3.0913, Train: 1.1329, Val: 1.1602, Test: 1.1612\n",
      "Epoch: 099, Loss: 3.0764, Train: 1.1292, Val: 1.1575, Test: 1.1584\n",
      "Epoch: 100, Loss: 3.0613, Train: 1.1259, Val: 1.1551, Test: 1.1560\n",
      "Epoch: 101, Loss: 3.0464, Train: 1.1237, Val: 1.1537, Test: 1.1546\n",
      "Epoch: 102, Loss: 3.0325, Train: 1.1227, Val: 1.1536, Test: 1.1545\n",
      "Epoch: 103, Loss: 3.0189, Train: 1.1225, Val: 1.1543, Test: 1.1552\n",
      "Epoch: 104, Loss: 3.0056, Train: 1.1224, Val: 1.1550, Test: 1.1560\n",
      "Epoch: 105, Loss: 2.9926, Train: 1.1217, Val: 1.1550, Test: 1.1562\n",
      "Epoch: 106, Loss: 2.9799, Train: 1.1199, Val: 1.1539, Test: 1.1552\n",
      "Epoch: 107, Loss: 2.9673, Train: 1.1175, Val: 1.1522, Test: 1.1537\n",
      "Epoch: 108, Loss: 2.9551, Train: 1.1158, Val: 1.1511, Test: 1.1528\n",
      "Epoch: 109, Loss: 2.9432, Train: 1.1154, Val: 1.1511, Test: 1.1531\n",
      "Epoch: 110, Loss: 2.9315, Train: 1.1156, Val: 1.1517, Test: 1.1540\n",
      "Epoch: 111, Loss: 2.9203, Train: 1.1155, Val: 1.1522, Test: 1.1547\n",
      "Epoch: 112, Loss: 2.9097, Train: 1.1146, Val: 1.1517, Test: 1.1545\n",
      "Epoch: 113, Loss: 2.8990, Train: 1.1128, Val: 1.1504, Test: 1.1534\n",
      "Epoch: 114, Loss: 2.8887, Train: 1.1107, Val: 1.1491, Test: 1.1521\n",
      "Epoch: 115, Loss: 2.8786, Train: 1.1095, Val: 1.1484, Test: 1.1516\n",
      "Epoch: 116, Loss: 2.8689, Train: 1.1091, Val: 1.1487, Test: 1.1519\n",
      "Epoch: 117, Loss: 2.8593, Train: 1.1091, Val: 1.1491, Test: 1.1524\n",
      "Epoch: 118, Loss: 2.8499, Train: 1.1079, Val: 1.1484, Test: 1.1519\n",
      "Epoch: 119, Loss: 2.8406, Train: 1.1055, Val: 1.1466, Test: 1.1502\n",
      "Epoch: 120, Loss: 2.8321, Train: 1.1043, Val: 1.1459, Test: 1.1496\n",
      "Epoch: 121, Loss: 2.8226, Train: 1.1034, Val: 1.1454, Test: 1.1493\n",
      "Epoch: 122, Loss: 2.8140, Train: 1.1027, Val: 1.1452, Test: 1.1492\n",
      "Epoch: 123, Loss: 2.8054, Train: 1.1022, Val: 1.1450, Test: 1.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124, Loss: 2.7969, Train: 1.1010, Val: 1.1443, Test: 1.1484\n",
      "Epoch: 125, Loss: 2.7885, Train: 1.0992, Val: 1.1431, Test: 1.1471\n",
      "Epoch: 126, Loss: 2.7801, Train: 1.0976, Val: 1.1420, Test: 1.1460\n",
      "Epoch: 127, Loss: 2.7719, Train: 1.0969, Val: 1.1418, Test: 1.1458\n",
      "Epoch: 128, Loss: 2.7639, Train: 1.0964, Val: 1.1417, Test: 1.1456\n",
      "Epoch: 129, Loss: 2.7559, Train: 1.0952, Val: 1.1410, Test: 1.1447\n",
      "Epoch: 130, Loss: 2.7482, Train: 1.0939, Val: 1.1404, Test: 1.1440\n",
      "Epoch: 131, Loss: 2.7404, Train: 1.0929, Val: 1.1399, Test: 1.1434\n",
      "Epoch: 132, Loss: 2.7330, Train: 1.0918, Val: 1.1394, Test: 1.1429\n",
      "Epoch: 133, Loss: 2.7255, Train: 1.0911, Val: 1.1392, Test: 1.1425\n",
      "Epoch: 134, Loss: 2.7181, Train: 1.0901, Val: 1.1387, Test: 1.1419\n",
      "Epoch: 135, Loss: 2.7111, Train: 1.0890, Val: 1.1382, Test: 1.1413\n",
      "Epoch: 136, Loss: 2.7039, Train: 1.0879, Val: 1.1377, Test: 1.1407\n",
      "Epoch: 137, Loss: 2.6969, Train: 1.0870, Val: 1.1375, Test: 1.1404\n",
      "Epoch: 138, Loss: 2.6901, Train: 1.0865, Val: 1.1374, Test: 1.1402\n",
      "Epoch: 139, Loss: 2.6834, Train: 1.0855, Val: 1.1369, Test: 1.1397\n",
      "Epoch: 140, Loss: 2.6769, Train: 1.0842, Val: 1.1361, Test: 1.1389\n",
      "Epoch: 141, Loss: 2.6704, Train: 1.0832, Val: 1.1357, Test: 1.1386\n",
      "Epoch: 142, Loss: 2.6640, Train: 1.0826, Val: 1.1358, Test: 1.1389\n",
      "Epoch: 143, Loss: 2.6577, Train: 1.0820, Val: 1.1358, Test: 1.1390\n",
      "Epoch: 144, Loss: 2.6517, Train: 1.0814, Val: 1.1356, Test: 1.1388\n",
      "Epoch: 145, Loss: 2.6454, Train: 1.0800, Val: 1.1348, Test: 1.1380\n",
      "Epoch: 146, Loss: 2.6394, Train: 1.0789, Val: 1.1346, Test: 1.1379\n",
      "Epoch: 147, Loss: 2.6335, Train: 1.0791, Val: 1.1353, Test: 1.1386\n",
      "Epoch: 148, Loss: 2.6276, Train: 1.0785, Val: 1.1354, Test: 1.1387\n",
      "Epoch: 149, Loss: 2.6219, Train: 1.0767, Val: 1.1346, Test: 1.1378\n",
      "Epoch: 150, Loss: 2.6162, Train: 1.0758, Val: 1.1343, Test: 1.1376\n",
      "Epoch: 151, Loss: 2.6106, Train: 1.0755, Val: 1.1347, Test: 1.1382\n",
      "Epoch: 152, Loss: 2.6050, Train: 1.0750, Val: 1.1350, Test: 1.1385\n",
      "Epoch: 153, Loss: 2.5996, Train: 1.0750, Val: 1.1357, Test: 1.1393\n",
      "Epoch: 154, Loss: 2.5937, Train: 1.0754, Val: 1.1369, Test: 1.1408\n",
      "Epoch: 155, Loss: 2.5880, Train: 1.0702, Val: 1.1332, Test: 1.1369\n",
      "Epoch: 156, Loss: 2.5818, Train: 1.0711, Val: 1.1345, Test: 1.1381\n",
      "Epoch: 157, Loss: 2.5750, Train: 1.0765, Val: 1.1397, Test: 1.1436\n",
      "Epoch: 158, Loss: 2.5685, Train: 1.0738, Val: 1.1387, Test: 1.1426\n",
      "Epoch: 159, Loss: 2.5611, Train: 1.0683, Val: 1.1349, Test: 1.1387\n",
      "Epoch: 160, Loss: 2.5539, Train: 1.0742, Val: 1.1410, Test: 1.1452\n",
      "Epoch: 161, Loss: 2.5464, Train: 1.0689, Val: 1.1366, Test: 1.1408\n",
      "Epoch: 162, Loss: 2.5385, Train: 1.0687, Val: 1.1368, Test: 1.1409\n",
      "Epoch: 163, Loss: 2.5309, Train: 1.0700, Val: 1.1386, Test: 1.1428\n",
      "Epoch: 164, Loss: 2.5237, Train: 1.0633, Val: 1.1332, Test: 1.1374\n",
      "Epoch: 165, Loss: 2.5164, Train: 1.0682, Val: 1.1388, Test: 1.1434\n",
      "Epoch: 166, Loss: 2.5091, Train: 1.0556, Val: 1.1277, Test: 1.1323\n",
      "Epoch: 167, Loss: 2.5021, Train: 1.0704, Val: 1.1422, Test: 1.1474\n",
      "Epoch: 168, Loss: 2.4964, Train: 1.0431, Val: 1.1172, Test: 1.1219\n",
      "Epoch: 169, Loss: 2.4908, Train: 1.0655, Val: 1.1369, Test: 1.1429\n",
      "Epoch: 170, Loss: 2.4821, Train: 1.0553, Val: 1.1292, Test: 1.1350\n",
      "Epoch: 171, Loss: 2.4729, Train: 1.0421, Val: 1.1185, Test: 1.1244\n",
      "Epoch: 172, Loss: 2.4685, Train: 1.0695, Val: 1.1431, Test: 1.1507\n",
      "Epoch: 173, Loss: 2.4645, Train: 1.0330, Val: 1.1108, Test: 1.1175\n",
      "Epoch: 174, Loss: 2.4596, Train: 1.0593, Val: 1.1341, Test: 1.1417\n",
      "Epoch: 175, Loss: 2.4489, Train: 1.0474, Val: 1.1236, Test: 1.1308\n",
      "Epoch: 176, Loss: 2.4409, Train: 1.0343, Val: 1.1119, Test: 1.1188\n",
      "Epoch: 177, Loss: 2.4364, Train: 1.0623, Val: 1.1372, Test: 1.1454\n",
      "Epoch: 178, Loss: 2.4330, Train: 1.0246, Val: 1.1053, Test: 1.1117\n",
      "Epoch: 179, Loss: 2.4301, Train: 1.0651, Val: 1.1411, Test: 1.1496\n",
      "Epoch: 180, Loss: 2.4235, Train: 1.0238, Val: 1.1060, Test: 1.1125\n",
      "Epoch: 181, Loss: 2.4164, Train: 1.0554, Val: 1.1336, Test: 1.1419\n",
      "Epoch: 182, Loss: 2.4075, Train: 1.0301, Val: 1.1121, Test: 1.1193\n",
      "Epoch: 183, Loss: 2.3991, Train: 1.0399, Val: 1.1209, Test: 1.1290\n",
      "Epoch: 184, Loss: 2.3916, Train: 1.0389, Val: 1.1207, Test: 1.1290\n",
      "Epoch: 185, Loss: 2.3858, Train: 1.0270, Val: 1.1103, Test: 1.1186\n",
      "Epoch: 186, Loss: 2.3813, Train: 1.0509, Val: 1.1331, Test: 1.1421\n",
      "Epoch: 187, Loss: 2.3800, Train: 1.0064, Val: 1.0933, Test: 1.1008\n",
      "Epoch: 188, Loss: 2.3854, Train: 1.0933, Val: 1.1681, Test: 1.1800\n",
      "Epoch: 189, Loss: 2.4267, Train: 0.9744, Val: 1.0668, Test: 1.0716\n",
      "Epoch: 190, Loss: 2.4946, Train: 1.1145, Val: 1.1885, Test: 1.1988\n",
      "Epoch: 191, Loss: 2.4537, Train: 1.0010, Val: 1.0869, Test: 1.0930\n",
      "Epoch: 192, Loss: 2.3729, Train: 0.9974, Val: 1.0830, Test: 1.0898\n",
      "Epoch: 193, Loss: 2.3751, Train: 1.0806, Val: 1.1588, Test: 1.1684\n",
      "Epoch: 194, Loss: 2.3902, Train: 1.0022, Val: 1.0935, Test: 1.0988\n",
      "Epoch: 195, Loss: 2.3725, Train: 1.0290, Val: 1.1178, Test: 1.1245\n",
      "Epoch: 196, Loss: 2.3465, Train: 1.0670, Val: 1.1494, Test: 1.1597\n",
      "Epoch: 197, Loss: 2.3580, Train: 0.9864, Val: 1.0794, Test: 1.0865\n",
      "Epoch: 198, Loss: 2.3738, Train: 1.0442, Val: 1.1283, Test: 1.1379\n",
      "Epoch: 199, Loss: 2.3386, Train: 1.0383, Val: 1.1258, Test: 1.1333\n",
      "Epoch: 200, Loss: 2.3268, Train: 1.0017, Val: 1.0943, Test: 1.0998\n",
      "Epoch: 201, Loss: 2.3431, Train: 1.0544, Val: 1.1397, Test: 1.1483\n",
      "Epoch: 202, Loss: 2.3276, Train: 1.0103, Val: 1.1000, Test: 1.1079\n",
      "Epoch: 203, Loss: 2.3116, Train: 1.0006, Val: 1.0925, Test: 1.1002\n",
      "Epoch: 204, Loss: 2.3121, Train: 1.0522, Val: 1.1391, Test: 1.1488\n",
      "Epoch: 205, Loss: 2.3130, Train: 0.9989, Val: 1.0944, Test: 1.1012\n",
      "Epoch: 206, Loss: 2.3158, Train: 1.0385, Val: 1.1285, Test: 1.1376\n",
      "Epoch: 207, Loss: 2.2955, Train: 1.0138, Val: 1.1053, Test: 1.1142\n",
      "Epoch: 208, Loss: 2.2869, Train: 0.9929, Val: 1.0889, Test: 1.0960\n",
      "Epoch: 209, Loss: 2.2902, Train: 1.0604, Val: 1.1472, Test: 1.1574\n",
      "Epoch: 210, Loss: 2.3073, Train: 0.9776, Val: 1.0761, Test: 1.0819\n",
      "Epoch: 211, Loss: 2.3237, Train: 1.0592, Val: 1.1461, Test: 1.1561\n",
      "Epoch: 212, Loss: 2.2996, Train: 0.9879, Val: 1.0840, Test: 1.0909\n",
      "Epoch: 213, Loss: 2.2716, Train: 1.0064, Val: 1.0999, Test: 1.1082\n",
      "Epoch: 214, Loss: 2.2562, Train: 1.0289, Val: 1.1228, Test: 1.1312\n",
      "Epoch: 215, Loss: 2.2561, Train: 0.9898, Val: 1.0898, Test: 1.0965\n",
      "Epoch: 216, Loss: 2.2603, Train: 1.0389, Val: 1.1309, Test: 1.1402\n",
      "Epoch: 217, Loss: 2.2652, Train: 0.9776, Val: 1.0806, Test: 1.0860\n",
      "Epoch: 218, Loss: 2.2643, Train: 1.0495, Val: 1.1424, Test: 1.1508\n",
      "Epoch: 219, Loss: 2.2625, Train: 0.9708, Val: 1.0730, Test: 1.0786\n",
      "Epoch: 220, Loss: 2.2612, Train: 1.0380, Val: 1.1302, Test: 1.1384\n",
      "Epoch: 221, Loss: 2.2494, Train: 0.9858, Val: 1.0884, Test: 1.0937\n",
      "Epoch: 222, Loss: 2.2300, Train: 1.0102, Val: 1.1106, Test: 1.1169\n",
      "Epoch: 223, Loss: 2.2112, Train: 1.0050, Val: 1.1044, Test: 1.1108\n",
      "Epoch: 224, Loss: 2.2103, Train: 0.9791, Val: 1.0855, Test: 1.0903\n",
      "Epoch: 225, Loss: 2.2133, Train: 1.0511, Val: 1.1492, Test: 1.1553\n",
      "Epoch: 226, Loss: 2.2387, Train: 0.9468, Val: 1.0552, Test: 1.0592\n",
      "Epoch: 227, Loss: 2.2877, Train: 1.0828, Val: 1.1696, Test: 1.1775\n",
      "Epoch: 228, Loss: 2.3317, Train: 0.9614, Val: 1.0675, Test: 1.0723\n",
      "Epoch: 229, Loss: 2.2537, Train: 1.0093, Val: 1.1114, Test: 1.1165\n",
      "Epoch: 230, Loss: 2.1918, Train: 1.0243, Val: 1.1208, Test: 1.1266\n",
      "Epoch: 231, Loss: 2.2038, Train: 0.9502, Val: 1.0591, Test: 1.0634\n",
      "Epoch: 232, Loss: 2.2359, Train: 1.0550, Val: 1.1545, Test: 1.1597\n",
      "Epoch: 233, Loss: 2.2283, Train: 0.9612, Val: 1.0707, Test: 1.0744\n",
      "Epoch: 234, Loss: 2.1832, Train: 0.9926, Val: 1.0970, Test: 1.1011\n",
      "Epoch: 235, Loss: 2.1548, Train: 1.0166, Val: 1.1216, Test: 1.1258\n",
      "Epoch: 236, Loss: 2.1620, Train: 0.9614, Val: 1.0713, Test: 1.0754\n",
      "Epoch: 237, Loss: 2.1704, Train: 1.0259, Val: 1.1243, Test: 1.1303\n",
      "Epoch: 238, Loss: 2.2053, Train: 0.9742, Val: 1.0866, Test: 1.0904\n",
      "Epoch: 239, Loss: 2.1758, Train: 1.0066, Val: 1.1171, Test: 1.1209\n",
      "Epoch: 240, Loss: 2.1601, Train: 0.9934, Val: 1.1005, Test: 1.1046\n",
      "Epoch: 241, Loss: 2.1307, Train: 0.9591, Val: 1.0687, Test: 1.0726\n",
      "Epoch: 242, Loss: 2.1478, Train: 1.0106, Val: 1.1218, Test: 1.1245\n",
      "Epoch: 243, Loss: 2.1489, Train: 0.9839, Val: 1.0978, Test: 1.1007\n",
      "Epoch: 244, Loss: 2.1375, Train: 0.9865, Val: 1.0961, Test: 1.1004\n",
      "Epoch: 245, Loss: 2.1126, Train: 0.9752, Val: 1.0863, Test: 1.0907\n",
      "Epoch: 246, Loss: 2.1114, Train: 0.9831, Val: 1.1001, Test: 1.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247, Loss: 2.1220, Train: 1.0117, Val: 1.1264, Test: 1.1280\n",
      "Epoch: 248, Loss: 2.1288, Train: 0.9460, Val: 1.0615, Test: 1.0647\n",
      "Epoch: 249, Loss: 2.1221, Train: 1.0200, Val: 1.1231, Test: 1.1285\n",
      "Epoch: 250, Loss: 2.1818, Train: 0.9596, Val: 1.0770, Test: 1.0793\n",
      "Epoch: 251, Loss: 2.1960, Train: 1.0466, Val: 1.1597, Test: 1.1616\n",
      "Epoch: 252, Loss: 2.2348, Train: 0.9422, Val: 1.0593, Test: 1.0610\n",
      "Epoch: 253, Loss: 2.1808, Train: 1.0341, Val: 1.1319, Test: 1.1376\n",
      "Epoch: 254, Loss: 2.2712, Train: 0.9596, Val: 1.0759, Test: 1.0780\n",
      "Epoch: 255, Loss: 2.1053, Train: 0.9846, Val: 1.1017, Test: 1.1036\n",
      "Epoch: 256, Loss: 2.1356, Train: 1.0288, Val: 1.1426, Test: 1.1452\n",
      "Epoch: 257, Loss: 2.1451, Train: 0.9319, Val: 1.0492, Test: 1.0524\n",
      "Epoch: 258, Loss: 2.1635, Train: 1.0220, Val: 1.1236, Test: 1.1289\n",
      "Epoch: 259, Loss: 2.2336, Train: 0.9815, Val: 1.1010, Test: 1.1010\n",
      "Epoch: 260, Loss: 2.0880, Train: 0.9623, Val: 1.0818, Test: 1.0841\n",
      "Epoch: 261, Loss: 2.1994, Train: 1.0732, Val: 1.1847, Test: 1.1879\n",
      "Epoch: 262, Loss: 2.2413, Train: 0.9263, Val: 1.0429, Test: 1.0460\n",
      "Epoch: 263, Loss: 2.2284, Train: 0.9945, Val: 1.0971, Test: 1.1042\n",
      "Epoch: 264, Loss: 2.1985, Train: 1.0249, Val: 1.1348, Test: 1.1383\n",
      "Epoch: 265, Loss: 2.1084, Train: 0.9394, Val: 1.0568, Test: 1.0605\n",
      "Epoch: 266, Loss: 2.2555, Train: 1.0339, Val: 1.1492, Test: 1.1524\n",
      "Epoch: 267, Loss: 2.1544, Train: 0.9925, Val: 1.1087, Test: 1.1138\n",
      "Epoch: 268, Loss: 2.0641, Train: 0.9332, Val: 1.0496, Test: 1.0553\n",
      "Epoch: 269, Loss: 2.1328, Train: 0.9880, Val: 1.0979, Test: 1.1053\n",
      "Epoch: 270, Loss: 2.0975, Train: 0.9952, Val: 1.1138, Test: 1.1168\n",
      "Epoch: 271, Loss: 2.0607, Train: 0.9566, Val: 1.0786, Test: 1.0807\n",
      "Epoch: 272, Loss: 2.1334, Train: 1.0128, Val: 1.1318, Test: 1.1348\n",
      "Epoch: 273, Loss: 2.0886, Train: 0.9728, Val: 1.0914, Test: 1.0964\n",
      "Epoch: 274, Loss: 2.0306, Train: 0.9414, Val: 1.0582, Test: 1.0645\n",
      "Epoch: 275, Loss: 2.0911, Train: 0.9677, Val: 1.0871, Test: 1.0916\n",
      "Epoch: 276, Loss: 2.0206, Train: 0.9890, Val: 1.1119, Test: 1.1137\n",
      "Epoch: 277, Loss: 2.0416, Train: 0.9637, Val: 1.0906, Test: 1.0917\n",
      "Epoch: 278, Loss: 2.0572, Train: 0.9804, Val: 1.1055, Test: 1.1076\n",
      "Epoch: 279, Loss: 2.0167, Train: 0.9597, Val: 1.0812, Test: 1.0864\n",
      "Epoch: 280, Loss: 2.0277, Train: 0.9369, Val: 1.0629, Test: 1.0665\n",
      "Epoch: 281, Loss: 2.0306, Train: 1.0042, Val: 1.1244, Test: 1.1282\n",
      "Epoch: 282, Loss: 2.0332, Train: 0.9499, Val: 1.0763, Test: 1.0789\n",
      "Epoch: 283, Loss: 2.0136, Train: 0.9572, Val: 1.0825, Test: 1.0858\n",
      "Epoch: 284, Loss: 1.9923, Train: 0.9727, Val: 1.0945, Test: 1.0996\n",
      "Epoch: 285, Loss: 2.0049, Train: 0.9363, Val: 1.0655, Test: 1.0684\n",
      "Epoch: 286, Loss: 2.0188, Train: 0.9950, Val: 1.1183, Test: 1.1227\n",
      "Epoch: 287, Loss: 2.0127, Train: 0.9445, Val: 1.0732, Test: 1.0765\n",
      "Epoch: 288, Loss: 1.9796, Train: 0.9419, Val: 1.0700, Test: 1.0730\n",
      "Epoch: 289, Loss: 1.9813, Train: 0.9712, Val: 1.0983, Test: 1.1009\n",
      "Epoch: 290, Loss: 1.9759, Train: 0.9484, Val: 1.0796, Test: 1.0818\n",
      "Epoch: 291, Loss: 1.9811, Train: 0.9672, Val: 1.0952, Test: 1.0992\n",
      "Epoch: 292, Loss: 1.9686, Train: 0.9423, Val: 1.0732, Test: 1.0766\n",
      "Epoch: 293, Loss: 1.9612, Train: 0.9484, Val: 1.0806, Test: 1.0830\n",
      "Epoch: 294, Loss: 1.9555, Train: 0.9693, Val: 1.0992, Test: 1.1024\n",
      "Epoch: 295, Loss: 1.9629, Train: 0.9287, Val: 1.0636, Test: 1.0666\n",
      "Epoch: 296, Loss: 1.9810, Train: 0.9913, Val: 1.1154, Test: 1.1215\n",
      "Epoch: 297, Loss: 2.0092, Train: 0.9257, Val: 1.0608, Test: 1.0643\n",
      "Epoch: 298, Loss: 1.9907, Train: 0.9781, Val: 1.1076, Test: 1.1122\n",
      "Epoch: 299, Loss: 1.9637, Train: 0.9382, Val: 1.0724, Test: 1.0756\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 300):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6fd7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies = len(movie_mapping)\n",
    "num_users = len(user_mapping)\n",
    "\n",
    "reverse_movie_mapping = dict(zip(movie_mapping.values(),movie_mapping.keys()))\n",
    "reverse_user_mapping = dict(zip(user_mapping.values(),user_mapping.keys()))\n",
    "\n",
    "results = []\n",
    "\n",
    "for user_id in range(0,num_users): \n",
    "\n",
    "    row = torch.tensor([user_id] * num_movies)\n",
    "    col = torch.arange(num_movies)\n",
    "    edge_label_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "\n",
    "    user_neo4j_id = reverse_user_mapping[user_id]\n",
    "\n",
    "    mask = (pred == 5).nonzero(as_tuple=True)\n",
    "\n",
    "    ten_predictions = [reverse_movie_mapping[el] for el in  mask[0].tolist()[:20]]\n",
    "    results.append({'user': user_neo4j_id, 'movies': ten_predictions})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32631420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_predictions_query = \"\"\"\n",
    "UNWIND $data AS row\n",
    "MATCH (u:User {userId: row.user})\n",
    "WITH u, row\n",
    "UNWIND row.movies AS movieId\n",
    "MATCH (m:Movie {movieId: movieId})\n",
    "WITH u,m\n",
    "// filter out existing links\n",
    "WHERE NOT (u)-[:RATED]->(m)\n",
    "MERGE (u)-[:RECOMMEND]->(m)\n",
    "\"\"\"\n",
    "\n",
    "fetch_data(import_predictions_query, {'data': results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "475eec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = fetch_data(\"\"\"\n",
    "MATCH (u:User{userId: $user})-[r:RECOMMEND]->(m) RETURN u.userId AS userId,m.movieId AS movieId,m.title AS title LIMIT 25\n",
    "\"\"\", {'user':14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed5a1593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>90061</td>\n",
       "      <td>The Myth of the American Sleepover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>143859</td>\n",
       "      <td>Hail, Caesar!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>4584</td>\n",
       "      <td>Dream a Little Dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>61250</td>\n",
       "      <td>The House Bunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>114265</td>\n",
       "      <td>Laggies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>33312</td>\n",
       "      <td>The Cocoanuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>94939</td>\n",
       "      <td>Sound of Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>105593</td>\n",
       "      <td>Filth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>91690</td>\n",
       "      <td>Friends with Kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>67788</td>\n",
       "      <td>Confessions of a Shopaholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>103539</td>\n",
       "      <td>The Spectacular Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>52319</td>\n",
       "      <td>The Inglorious Bastards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>79469</td>\n",
       "      <td>The Northerners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>6850</td>\n",
       "      <td>Leap of Faith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2849</td>\n",
       "      <td>Queens Logic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>4717</td>\n",
       "      <td>The Big Brawl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>107559</td>\n",
       "      <td>Death of a Superhero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>2880</td>\n",
       "      <td>Armour of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>4741</td>\n",
       "      <td>Together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>101962</td>\n",
       "      <td>Wolf Children</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId                               title\n",
       "0       14    90061  The Myth of the American Sleepover\n",
       "1       14   143859                       Hail, Caesar!\n",
       "2       14     4584                Dream a Little Dream\n",
       "3       14    61250                     The House Bunny\n",
       "4       14   114265                             Laggies\n",
       "5       14    33312                       The Cocoanuts\n",
       "6       14    94939                      Sound of Noise\n",
       "7       14   105593                               Filth\n",
       "8       14    91690                   Friends with Kids\n",
       "9       14    67788         Confessions of a Shopaholic\n",
       "10      14   103539                 The Spectacular Now\n",
       "11      14    52319             The Inglorious Bastards\n",
       "12      14    79469                     The Northerners\n",
       "13      14     6850                       Leap of Faith\n",
       "14      14     2849                        Queens Logic\n",
       "15      14     4717                       The Big Brawl\n",
       "16      14   107559                Death of a Superhero\n",
       "17      14     2880                       Armour of God\n",
       "18      14     4741                            Together\n",
       "19      14   101962                       Wolf Children"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c5cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('liked_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18325b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userId, movieId, title, rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.merge(col,test,on=['userId','movieId'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1267740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>551</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>349</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>589</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>5669</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>44191</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1197</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2318</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2028</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2841</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>1235</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>1222</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>1033</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>2100</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>2628</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>1240</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>2723</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>1197</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>3060</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>1288</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>1196</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>2872</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>1580</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>1396</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "0        1     1029     3.0\n",
       "1        2       50     4.0\n",
       "2        2      551     5.0\n",
       "3        2      153     4.0\n",
       "4        2       10     4.0\n",
       "5        2      349     4.0\n",
       "6        2      589     5.0\n",
       "7        2      150     5.0\n",
       "8        3     5669     3.5\n",
       "9        3    44191     3.5\n",
       "10       3     1197     5.0\n",
       "11       3     2318     4.0\n",
       "12       3     2028     4.0\n",
       "13       3     2841     4.0\n",
       "14       3     1235     4.0\n",
       "15       4      296     5.0\n",
       "16       4     2018     5.0\n",
       "17       4     1222     5.0\n",
       "18       4     1033     5.0\n",
       "19       4     2100     5.0\n",
       "20       4     2628     5.0\n",
       "21       4     1240     5.0\n",
       "22       4     2723     5.0\n",
       "23       4     1197     5.0\n",
       "24       4     3060     5.0\n",
       "25       4     1288     5.0\n",
       "26       4     1196     5.0\n",
       "27       4     2872     5.0\n",
       "28       4     1580     5.0\n",
       "29       4     1396     5.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ba8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f199cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920b337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b262ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
